<?xml version="1.0" encoding="UTF-8"?>
<hdevelop file_version="1.2" halcon_version="23.05.0.0">
<procedure name="main">
<interface/>
<body>
<l>dev_update_off ()</l>
<l>dev_close_window ()</l>
<l>* set_system ('seed_rand', 73)</l>
<c>*模型名称</c>
<l>TrainedModel := 'detect_juice_bottle_gc_anomalies.hdl'</l>
<c>*测试图</c>
<l>list_files ('测试图', ['files','follow_links'], ImageFiles)</l>
<c>*读模型</c>
<l>read_dl_model (TrainedModel, DLModelHandle)</l>
<c>*预处理参数</c>
<l>create_dl_preprocess_param_from_model (DLModelHandle, 'none', 'full_domain', [], [], [], DLPreprocessParam)</l>
<c>*取得模型参数，主要是获得两个阈值</c>
<l>get_dl_model_param (DLModelHandle, 'meta_data', MetaData)</l>
<l>SegmentationThreshold := number(MetaData.anomaly_segmentation_threshold)</l>
<l>ClassificationThreshold := number(MetaData.anomaly_classification_threshold)</l>
<c>* 字典生成，仅仅是为了显示.</c>
<l>DLDatasetInfo := dict{class_names: ['ok', 'nok'], class_ids: [0, 1]}</l>
<c>*循环推理</c>
<l>list_image_files ('D:/desk/果汁异常检测/测试图', 'default', 'follow_links', ImageFiles)</l>
<c></c>
<c>*循环读图和推理</c>
<l>for Index := 0 to |ImageFiles|-1 by 1</l>
<l>    read_image (Image, ImageFiles[Index])</l>
<l>    get_image_size (Image, Width, Height)</l>
<l>    gen_dl_samples_from_images (Image, DLSample)</l>
<l>    preprocess_dl_samples (DLSample, DLPreprocessParam)</l>
<l>    apply_dl_model (DLModelHandle, DLSample, ['anomaly_image_local', 'anomaly_image_global'], DLResult)</l>
<l>    zoom_image_size (DLResult.anomaly_image_global, ImageZoom, Width, Height, 'constant')</l>
<l>    get_dict_object (AnomalyImage, DLResult, 'anomaly_image_global')</l>
<l>    threshold (ImageZoom, AnomalyRegion, SegmentationThreshold, 'max')</l>
<l>    get_dict_tuple (DLResult, 'anomaly_score_global', AnomalyScore)                 </l>
<l>    dev_set_draw ('margin')</l>
<l>    dev_display (Image)</l>
<l>    dev_display (AnomalyRegion)</l>
<l>    if (AnomalyScore &lt; ClassificationThreshold)</l>
<l>        Text := 'OK'</l>
<l>        BoxColor := 'green'</l>
<l>    else</l>
<l>        Text := 'NOK'</l>
<l>        BoxColor := 'red'</l>
<l>    endif</l>
<l>    dev_disp_text (Text, 'window', 'top', 'left', 'black', ['box_color', 'shadow'], [BoxColor,'false'])</l>
<l>    stop ()</l>
<l>endfor</l>
<c></c>
</body>
<docu id="main">
<parameters/>
</docu>
</procedure>
<procedure name="get_example_inference_images">
<interface>
<ic>
<par name="ImageDir" base_type="ctrl" dimension="0"/>
<par name="NumSamples" base_type="ctrl" dimension="0"/>
</ic>
<oc>
<par name="ImageFiles" base_type="ctrl" dimension="0"/>
</oc>
</interface>
<body>
<c>* This procedure creates a list of images used for this example.</c>
<c>* </c>
<l>list_image_files (ImageDir, 'default', 'recursive', ImageFilesAll)</l>
<l>tuple_shuffle (ImageFilesAll, ImageFilesAll)</l>
<l>ImageFiles := ImageFilesAll[0:NumSamples - 1]</l>
<c>* </c>
<l>return ()</l>
</body>
<docu id="get_example_inference_images">
<parameters>
<parameter id="ImageDir"/>
<parameter id="ImageFiles"/>
<parameter id="NumSamples"/>
</parameters>
</docu>
</procedure>
<procedure name="inference">
<interface>
<ic>
<par name="DLDataset" base_type="ctrl" dimension="0"/>
<par name="DLPreprocessParam" base_type="ctrl" dimension="0"/>
<par name="DLModelHandle" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* In this local example procedure, we apply the trained model</c>
<c>* to some randomly chosen images that have not been used during</c>
<c>* training.</c>
<c></c>
<l>display_info_text ('inference')</l>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<l>MaxNumInferenceImages := 10</l>
<l>get_random_test_image_paths (DLDataset, MaxNumInferenceImages, InferenceImagePaths)</l>
<c></c>
<c>* Get thresholds for inference. These have been stored along with</c>
<c>* the model in the meta data.</c>
<l>get_dl_model_param (DLModelHandle, 'meta_data', MetaData)</l>
<l>ClassificationThreshold := number(MetaData.anomaly_classification_threshold)</l>
<l>SegmentationThreshold := number(MetaData.anomaly_segmentation_threshold)</l>
<c></c>
<c>* Create a dictionary with dataset parameters used for display.</c>
<l>DLDatasetInfo := dict{class_names: ['ok', 'nok'], class_ids: [0, 1]}</l>
<c></c>
<c>* Apply the model to test images.</c>
<l>WindowDict := dict{}</l>
<l>for IndexInference := 0 to |InferenceImagePaths| - 1 by 1</l>
<c></c>
<l>    read_image (Image, InferenceImagePaths[IndexInference])</l>
<l>gen_dl_samples_from_images (Image, DLSample)</l>
<l>preprocess_dl_samples (DLSample, DLPreprocessParam)</l>
<c></c>
<l>    apply_dl_model (DLModelHandle, DLSample, [], DLResult)</l>
<c></c>
<c>    * Apply thresholds to classify regions and the entire image.</c>
<l>threshold_dl_anomaly_results (SegmentationThreshold, ClassificationThreshold, DLResult)</l>
<c></c>
<c>    * Display the inference result.</c>
<l>dev_display_dl_data (DLSample, DLResult, DLDatasetInfo, ['anomaly_result', 'anomaly_image'], [], WindowDict)</l>
<l>    dev_disp_text ('Press F5 (continue)', 'window', 'bottom', 'center', 'black', [], [])</l>
<l>    stop ()</l>
<l>endfor</l>
<l>dev_close_window_dict (WindowDict)</l>
<l>return ()</l>
</body>
<docu id="inference">
<short lang="en_US">Apply the trained model to test images.</short>
<parameters>
<parameter id="DLDataset"/>
<parameter id="DLModelHandle"/>
<parameter id="DLPreprocessParam"/>
</parameters>
</docu>
</procedure>
<procedure name="clean_up_output">
<interface>
<ic>
<par name="PreprocessDir" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* This local example procedure removes the</c>
<c>* directory of the preprocessed dataset.</c>
<c></c>
<c>* Display a warning.</c>
<l>display_info_text ('clean_up')</l>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<l>remove_dir_recursively (PreprocessDir)</l>
<c></c>
<l>return ()</l>
</body>
<docu id="clean_up_output">
<short lang="en_US">Remove the preprocessed dataset generated by this example.</short>
<parameters>
<parameter id="PreprocessDir"/>
</parameters>
</docu>
</procedure>
<procedure name="train">
<interface>
<ic>
<par name="DLDataset" base_type="ctrl" dimension="0"/>
<par name="DLModelHandle" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* This local example procedure trains the GC-AD model.</c>
<c></c>
<l>display_info_text ('train')</l>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<c>* If the 'batch_size' is set to 1 the best results for</c>
<c>* GC-AD models can be expected.</c>
<l>set_dl_model_param (DLModelHandle, 'batch_size', 1)</l>
<c></c>
<c>* Use a GPU for training.</c>
<l>query_available_dl_devices (['runtime', 'id'], ['gpu', 0], DLDeviceHandle)</l>
<l>if (DLDeviceHandle == [])</l>
<l>    throw ('It is recommended to use a GPU for training, due to a long training time on the CPU.')</l>
<l>endif</l>
<c></c>
<c>* Set the chosen device. In case of memory difficulties modify</c>
<c>* the model parameters 'image_dimensions' or 'patch_size'.</c>
<l>set_dl_model_param (DLModelHandle, 'device', DLDeviceHandle)</l>
<c></c>
<c>* A good default for the number of training steps is 70,000.</c>
<c>* If just the local network should be trained we recommend</c>
<c>* a number of 35,000 training steps.</c>
<l>NumTrainSteps := 70000</l>
<c></c>
<c>* Convert the number of training steps to epochs.</c>
<l>find_dl_samples (DLDataset.samples, 'split', 'train', 'match', TrainSampleIndices)</l>
<l>NumEpochs := ceil(real(NumTrainSteps) / |TrainSampleIndices|)</l>
<c></c>
<c>* Data augmentation is important for training the global network.</c>
<c>* In this example, we rotate the images slightly and apply</c>
<c>* color jitter.</c>
<l>AugmentationDict := dict{}</l>
<l>AugmentationDict.augmentation_percentage := 100</l>
<l>AugmentationDict.rotate_range := 3</l>
<l>AugmentationDict.brightness_variation := 20</l>
<l>AugmentationDict.contrast_variation := 0.2</l>
<l>AugmentationDict.saturation_variation := 0.2</l>
<c></c>
<c>* Decay the learning rate after 95% of the epochs.</c>
<l>get_dl_model_param (DLModelHandle, 'learning_rate', InitialLR)</l>
<l>LRDecayDict := dict{}</l>
<l>LRDecayDict.model_param := 'learning_rate'</l>
<l>LRDecayDict.initial_value := InitialLR</l>
<l>LRDecayDict.epochs := 0.95 * NumEpochs</l>
<l>LRDecayDict.values := 0.1 * InitialLR</l>
<c></c>
<l>SerializationDict := dict{}</l>
<l>SerializationDict.type := 'current'</l>
<l>SerializationDict.basename := 'intermediate_dl_anomaly_global_context'</l>
<c></c>
<l>create_dl_train_param (DLModelHandle, NumEpochs, [], true, 73, ['augment', 'change', 'serialize'], [AugmentationDict,LRDecayDict,SerializationDict], TrainParam)</l>
<c></c>
<c>* The training and thus the call of train_dl_model_batch () is</c>
<c>* done using the following procedure. This may take a long time.</c>
<l>train_dl_model (DLDataset, DLModelHandle, TrainParam, 0, TrainResults, TrainInfos, EvaluationInfos)</l>
<c></c>
<c>* After training, it is very important to normalize the local and</c>
<c>* the global network.</c>
<l>normalize_dl_gc_anomaly_scores (DLDataset, DLModelHandle, [])</l>
<l>dev_disp_text ('Press Run (F5) to continue with the evaluation of the model', 'window', 'bottom', 'right', 'black', [], [])</l>
<l>stop ()</l>
<c></c>
<l>dev_close_window ()</l>
<l>return ()</l>
</body>
<docu id="train">
<short lang="en_US">Train the Global Context Anomaly Detection model.</short>
<parameters>
<parameter id="DLDataset"/>
<parameter id="DLModelHandle"/>
</parameters>
</docu>
</procedure>
<procedure name="get_random_test_image_paths">
<interface>
<ic>
<par name="DLDataset" base_type="ctrl" dimension="0"/>
<par name="MaxNumTestImages" base_type="ctrl" dimension="0"/>
</ic>
<oc>
<par name="ImagePaths" base_type="ctrl" dimension="0"/>
</oc>
</interface>
<body>
<c>* This procedure returns paths to randomly chosen test images.</c>
<c></c>
<c>* Get all test sample indices</c>
<l>DLSamples := DLDataset.samples</l>
<l>find_dl_samples (DLSamples, 'split', 'test', 'match', TestSampleIndices)</l>
<l>NumTestImages := min2(|TestSampleIndices|,MaxNumTestImages)</l>
<c></c>
<l>tuple_shuffle (TestSampleIndices, TestSampleIndicesShuffled)</l>
<c></c>
<l>ImagePaths := gen_tuple_const(NumTestImages,-1)</l>
<l>for Index := 0 to NumTestImages - 1 by 1</l>
<l>    SampleIndex := TestSampleIndicesShuffled[Index]</l>
<l>    DLSample := DLSamples[SampleIndex]</l>
<l>    ImagePath := DLDataset.image_dir + '/' + DLSample.image_file_name</l>
<l>    ImagePaths[Index] := ImagePath</l>
<l>endfor</l>
<l>return ()</l>
</body>
<docu id="get_random_test_image_paths">
<short lang="en_US">Return paths to randomly chosen test images.</short>
<parameters>
<parameter id="DLDataset">
<default_type>integer</default_type>
<description lang="en_US">A DLDataset that has been split.</description>
<mixed_type>false</mixed_type>
<multivalue>false</multivalue>
<sem_type>dict</sem_type>
<type_list>
<item>integer</item>
</type_list>
</parameter>
<parameter id="ImagePaths">
<description lang="en_US">Paths to the randomly chosen test images.</description>
<multivalue>true</multivalue>
<sem_type>string</sem_type>
</parameter>
<parameter id="MaxNumTestImages">
<default_type>integer</default_type>
<description lang="en_US">The maximum number of test images to return.</description>
<multivalue>false</multivalue>
<sem_type>number</sem_type>
<type_list>
<item>integer</item>
</type_list>
</parameter>
</parameters>
</docu>
</procedure>
<procedure name="evaluate">
<interface>
<ic>
<par name="DLDataset" base_type="ctrl" dimension="0"/>
<par name="DLModelHandle" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* This local example procedure calculates classification and</c>
<c>* segmentation thresholds and evaluates the performance of</c>
<c>* the trained model.</c>
<c></c>
<l>display_info_text ('evaluate')</l>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<c>* Estimate threshold values. They are used to determine if</c>
<c>* a pixel or image is regarded as anomalous. The procedure</c>
<c>* compute_dl_anomaly_thresholds returns possible suggestions</c>
<c>* based on the dataset used. Depending on the application,</c>
<c>* manual fine-tuning may be beneficial. See the documentation</c>
<c>* of compute_dl_anomaly_thresholds for details.</c>
<l>GenParamThreshold := dict{}</l>
<l>GenParamThreshold.enable_display := 'true'</l>
<l>GenParamThreshold.segmentation_criterion := 'tolerance'</l>
<l>GenParamThreshold.segmentation_tolerance := 0.0</l>
<l>compute_dl_anomaly_thresholds (DLModelHandle, DLDataset, GenParamThreshold, SegmentationThreshold, ClassificationThresholds)</l>
<l>dev_disp_text ('Press Run (F5) to continue', 'window', 'bottom', 'right', 'black', [], [])</l>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<c>* Set generic evaluation parameters and evaluate the model on the</c>
<c>* test split.</c>
<l>GenParamEvaluation := dict{}</l>
<l>GenParamEvaluation.measures := 'all'</l>
<l>GenParamEvaluation.anomaly_classification_thresholds := ClassificationThresholds</l>
<l>GenParamEvaluation.gc_anomaly_networks := ['local', 'global']</l>
<l>evaluate_dl_model (DLDataset, DLModelHandle, 'split', 'test', GenParamEvaluation, EvaluationResult, EvalParams)</l>
<c></c>
<c>* Visualize the histogram of the image-level anomaly scores of</c>
<c>* the test images and the classification thresholds used for the</c>
<c>* evaluation.</c>
<l>GenParamDisplay := dict{}</l>
<l>GenParamDisplay.display_mode := ['score_histogram', 'score_legend']</l>
<l>WindowDict := dict{}</l>
<l>dev_display_anomaly_detection_evaluation (EvaluationResult, EvalParams, GenParamDisplay, WindowDict)</l>
<l>dev_disp_text ('Press Run (F5) to continue', 'window', 'bottom', 'right', 'black', 'box', 'true')</l>
<l>stop ()</l>
<l>dev_close_window_dict (WindowDict)</l>
<c></c>
<c>* Visualize evaluation results such as precision, recall, and</c>
<c>* confusion matrix for a given classification threshold.</c>
<l>GenParamDisplay.display_mode := ['pie_charts_precision', 'pie_charts_recall', 'absolute_confusion_matrix']</l>
<c>* Select evaluation results for one threshold by its index in</c>
<c>* ClassificationThresholds for display. We use the last</c>
<c>* one of the computed ClassificationThresholds.</c>
<c>* Please note that you should check which ClassificationThreshold</c>
<c>* best fits your application.</c>
<l>ClassificationThresholdIndex := |ClassificationThresholds| - 1</l>
<l>GenParamDisplay.classification_threshold_index := ClassificationThresholdIndex</l>
<l>WindowDict := dict{}</l>
<l>dev_display_anomaly_detection_evaluation (EvaluationResult, EvalParams, GenParamDisplay, WindowDict)</l>
<l>dev_disp_text ('Press Run (F5) to continue', 'window', 'bottom', 'right', 'black', [], [])</l>
<l>stop ()</l>
<l>dev_close_window_dict (WindowDict)</l>
<c></c>
<c>* Set the threshold that should be returned.</c>
<l>ClassificationThreshold := ClassificationThresholds[ClassificationThresholdIndex]</l>
<c>* Store the thresholds in the model's meta data.</c>
<l>get_dl_model_param (DLModelHandle, 'meta_data', MetaData)</l>
<l>MetaData.anomaly_segmentation_threshold := SegmentationThreshold$'1.16e'</l>
<l>MetaData.anomaly_classification_threshold := ClassificationThreshold$'1.16e'</l>
<l>set_dl_model_param (DLModelHandle, 'meta_data', MetaData)</l>
<c></c>
<l>set_dl_model_param (DLModelHandle, 'optimize_for_inference', 'true')</l>
<l>return ()</l>
</body>
<docu id="evaluate">
<short lang="en_US">Calculate classification and segmentation thresholds and evaluate the trained model.</short>
<parameters>
<parameter id="DLDataset"/>
<parameter id="DLModelHandle"/>
</parameters>
</docu>
</procedure>
<procedure name="display_info_text">
<interface>
<ic>
<par name="Part" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* Helper procedure for displaying informative text at the</c>
<c>* start of each part of the workflow.</c>
<l>dev_open_window (0, 0, 500, 300, 'light gray', WindowHandle)</l>
<c></c>
<l>set_display_font (WindowHandle, 16, 'mono', 'true', 'false')</l>
<c>* Texts and Colors should have the same length.</c>
<c>* Colors contains the color for each text in Texts.</c>
<l>Texts := []</l>
<l>Colors := []</l>
<l>StandardColor := 'black'</l>
<l>FocusColor := '#f28d26'</l>
<l>if (Part == 'start')</l>
<l>    Colors := []</l>
<l>    Text := 'The workflow is split up into different'</l>
<l>    Text := Text + '\nparts which are encapsulated in '</l>
<l>    Text := Text + '\nseparate local procedures:'</l>
<l>    Text := Text + '\n\n1. load_dataset_and_model'</l>
<l>    Text := Text + '\n2. train'</l>
<l>    Text := Text + '\n3. evaluate'</l>
<l>    Text := Text + '\n4. inference'</l>
<l>    Text := Text + '\n5. compare_gc_anomaly_networks'</l>
<l>    Texts := [Texts,Text]</l>
<l>    Colors := [Colors,StandardColor]</l>
<c></c>
<l>    Text := '\nPress Run (F5) to enter the first procedure.'</l>
<l>    Texts := [Texts,Text]</l>
<l>    Colors := [Colors,StandardColor]</l>
<l>elseif (Part == 'clean_up')</l>
<l>    Text := 'Congratulations, you have finished the example.'</l>
<l>    Text := Text + '\n\nPress Run (F5) to remove the directory'</l>
<l>    Text := Text + '\nof the preprocessed dataset.'</l>
<l>    Texts := Text</l>
<l>    Colors := StandardColor</l>
<l>else</l>
<l>    Title := Part + '\n'</l>
<l>    if (Part == 'load_dataset_and_model')</l>
<l>        Body := 'In this part, the model is loaded and'</l>
<l>        Body := Body + '\nthe dataset is preprocessed. Then, randomly'</l>
<l>        Body := Body + '\nselected preprocessed images are shown.'</l>
<l>        Body := Body + '\n\nPress Run (F5) to continue.'</l>
<l>    elseif (Part == 'train')</l>
<l>        Body := 'In this part, the model is trained on'</l>
<l>        Body := Body + '\nanomaly-free (\'ok\') images.'</l>
<l>        Body := Body + '\nDepending on the GPU, the training'</l>
<l>        Body := Body + '\nmay take multiple hours.'</l>
<l>        Body := Body + '\n\nPress Run (F5) to continue.'</l>
<l>    elseif (Part == 'evaluate')</l>
<l>        Body := 'In this part, a classification threshold'</l>
<l>        Body := Body + '\nand a segmentation threshold are computed.'</l>
<l>        Body := Body + '\nThen, the model is evaluated on test images.'</l>
<l>        Body := Body + '\n\nPress Run (F5) to continue.'</l>
<l>    elseif (Part == 'inference')</l>
<l>        Body := 'In this part, the model is applied to some'</l>
<l>        Body := Body + '\ntest images that have not been used during'</l>
<l>        Body := Body + '\ntraining.'</l>
<l>        Body := Body + '\n\nPress Run (F5) to continue.'</l>
<l>    elseif (Part == 'compare_gc_anomaly_networks')</l>
<l>        Body := 'The GC-AD model consists of two subnetworks,'</l>
<l>        Body := Body + '\nthe local and the global network.'</l>
<l>        Body := Body + '\nIn this procedure, we visualize the'</l>
<l>        Body := Body + '\nanomaly images of each subnetwork.'</l>
<l>        Body := Body + '\n\nThis step is optional and can be skipped.'</l>
<l>        Body := Body + '\nPress Run (F5) to continue.'</l>
<l>    else</l>
<l>        throw ('Unknown part: ' + Part)</l>
<l>    endif</l>
<l>    Texts := [Title,Body]</l>
<l>    Colors := [FocusColor,StandardColor]</l>
<l>endif</l>
<c></c>
<c>* Color each text differently. For that, we need to find out the</c>
<c>* color of each line in the sum of strings in Texts.</c>
<l>LineColors := []</l>
<l>for TextIndex := 0 to |Texts| - 1 by 1</l>
<l>    Text := Texts[TextIndex]</l>
<l>    TextColor := Colors[TextIndex]</l>
<c>    * Find out how many lines Text has.</c>
<l>    NumLines := 1</l>
<l>    Position := strchr(Text,'\n')</l>
<l>    while (Position != -1)</l>
<l>        NumLines := NumLines + 1</l>
<l>        if (Position + 1 == strlen(Text))</l>
<l>            break</l>
<l>        endif</l>
<l>        Text := Text{Position + 1:strlen(Text) - 1}</l>
<l>        Position := strchr(Text,'\n')</l>
<l>    endwhile</l>
<c>    * Append TextColor to LineColors for each line in Text.</c>
<l>    for LineIndex := 0 to NumLines - 1 by 1</l>
<l>        LineColors := [LineColors,TextColor]</l>
<l>    endfor</l>
<l>endfor</l>
<c></c>
<l>dev_disp_text (join(Texts,'\n'), 'window', 'center', 'center', LineColors, 'box', 'false')</l>
<c></c>
<l>return ()</l>
</body>
<docu id="display_info_text">
<short lang="en_US">Display informative text about the progress of the example.</short>
<parameters>
<parameter id="Part"/>
</parameters>
</docu>
</procedure>
<procedure name="compare_gc_anomaly_networks">
<interface>
<ic>
<par name="ImageDir" base_type="ctrl" dimension="0"/>
<par name="ImageSubDirs" base_type="ctrl" dimension="0"/>
<par name="DLPreprocessParam" base_type="ctrl" dimension="0"/>
<par name="DLModelHandle" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* The GC-AD model consists of two subnetworks, the local and</c>
<c>* the global network. See the Chapter Reference for more</c>
<c>* details on this topic.</c>
<c></c>
<c>* In this local example procedure, we visualize the anomaly</c>
<c>* images of the local and the global network of the GC-AD model.</c>
<c></c>
<c>* For each defect type in the given ImageSubDirs, we pick 10</c>
<c>* images to which we apply the model. In the example dataset,</c>
<c>* the two defect types are 'logical_anomaly' and</c>
<c>* 'structural_anomaly'.</c>
<c></c>
<c>* As a result one should see that the local network is good at</c>
<c>* detecting structural anomalies, while the global network</c>
<c>* successfully finds logical anomalies. Some of the defects are</c>
<c>* detected by both subnetworks.</c>
<c></c>
<l>display_info_text ('compare_gc_anomaly_networks')</l>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<l>MaxNumImagesPerSubdir := 10</l>
<c></c>
<c>* Get thresholds for inference. These have been stored along with</c>
<c>* the model in the meta data.</c>
<l>get_dl_model_param (DLModelHandle, 'meta_data', MetaData)</l>
<l>ClassificationThreshold := number(MetaData.anomaly_classification_threshold)</l>
<l>SegmentationThreshold := number(MetaData.anomaly_segmentation_threshold)</l>
<c></c>
<c>* Create a dictionary with dataset parameters used for display.</c>
<l>DLDatasetInfo := dict{class_names: ['ok', 'nok'], class_ids: [0, 1]}</l>
<c></c>
<c>* Iterate over all subdirectories that contain defects.</c>
<l>for SubDirIndex := 0 to |ImageSubDirs| - 1 by 1</l>
<l>    SubDir := ImageSubDirs[SubDirIndex]</l>
<l>    if (regexp_match(SubDir,['^ok$', 'ignore_case']) != '' or regexp_match(SubDir,['^good$', 'ignore_case']) != '')</l>
<c>        * Skip the subdirectory, because it is named 'ok' or 'good'.</c>
<l>        continue</l>
<l>    endif</l>
<c></c>
<c>    * Get paths to randomly chosen images from this subdirectory.</c>
<l>list_image_files (ImageDir + '/' + SubDir, 'default', [], ImageFiles)</l>
<l>tuple_shuffle (ImageFiles, ImageFiles)</l>
<l>    ImagePaths := ImageFiles[0:MaxNumImagesPerSubdir - 1]</l>
<c></c>
<c>    * Infer images containing anomalies with the local and</c>
<c>    * the global network.</c>
<l>    WindowDict := dict{}</l>
<l>    for IndexInference := 0 to |ImagePaths| - 1 by 1</l>
<c></c>
<l>        read_image (Image, ImagePaths[IndexInference])</l>
<l>gen_dl_samples_from_images (Image, DLSample)</l>
<l>preprocess_dl_samples (DLSample, DLPreprocessParam)</l>
<c></c>
<l>        apply_dl_model (DLModelHandle, DLSample, ['anomaly_image_local', 'anomaly_image_global'], DLResult)</l>
<c></c>
<c>        * Apply thresholds to classify regions and the entire image.</c>
<l>threshold_dl_anomaly_results (SegmentationThreshold, ClassificationThreshold, DLResult)</l>
<c></c>
<c>        * Display the inference result.</c>
<l>dev_display_dl_data (DLSample, DLResult, DLDatasetInfo, ['image', 'anomaly_image_local', 'anomaly_image_global'], [], WindowDict)</l>
<l>        Text := 'Defect type:\n' + SubDir + '\n\nPress F5 (continue)'</l>
<l>        dev_disp_text (Text, 'window', 'bottom', 'center', 'black', [], [])</l>
<l>        stop ()</l>
<l>    endfor</l>
<l>dev_close_window_dict (WindowDict)</l>
<l>endfor</l>
<l>return ()</l>
</body>
<docu id="compare_gc_anomaly_networks">
<short lang="en_US">Visualize the anomaly images of the local and the global network of the Global Context Anomaly Detection model.</short>
<parameters>
<parameter id="DLModelHandle"/>
<parameter id="DLPreprocessParam"/>
<parameter id="ImageDir"/>
<parameter id="ImageSubDirs"/>
</parameters>
</docu>
</procedure>
<procedure name="get_image_dir">
<interface>
<oc>
<par name="ImageDir" base_type="ctrl" dimension="0"/>
</oc>
</interface>
<body>
<l>get_system ('image_dir', ImageDir)</l>
<l>get_system ('operating_system', OperatingSystem)</l>
<l>IsWindows := OperatingSystem{0:2} == 'Win'</l>
<l>if (IsWindows)</l>
<l>    Separator := ';'</l>
<l>else</l>
<l>    Separator := ':'</l>
<l>endif</l>
<l>tuple_split (ImageDir, Separator, ImageDir)</l>
<l>ImageDir := ImageDir[0]</l>
<l>ImageDir := regexp_replace(ImageDir,['\\\\+', 'replace_all'],'/')</l>
<l>return ()</l>
</body>
<docu id="get_image_dir">
<short lang="en_US">Return the path to the HALCON images directory.</short>
<parameters>
<parameter id="ImageDir"/>
</parameters>
</docu>
</procedure>
<procedure name="load_dataset_and_model">
<interface>
<ic>
<par name="TrainedModel" base_type="ctrl" dimension="0"/>
<par name="ImageDir" base_type="ctrl" dimension="0"/>
<par name="ImageSubDirs" base_type="ctrl" dimension="0"/>
<par name="ImageWidth" base_type="ctrl" dimension="0"/>
<par name="ImageHeight" base_type="ctrl" dimension="0"/>
<par name="PatchSize" base_type="ctrl" dimension="0"/>
</ic>
<oc>
<par name="DLDataset" base_type="ctrl" dimension="0"/>
<par name="DLPreprocessParam" base_type="ctrl" dimension="0"/>
<par name="PreprocessDir" base_type="ctrl" dimension="0"/>
<par name="DLModelHandle" base_type="ctrl" dimension="0"/>
</oc>
</interface>
<body>
<c>* This local example procedure loads the Global Context Anomaly</c>
<c>* Detection model and preprocesses the dataset.</c>
<c></c>
<l>display_info_text ('load_dataset_and_model')</l>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<c>* Folder where the preprocessed samples will be stored.</c>
<l>PreprocessDir := './anomaly_juice_bottle_data'</l>
<c></c>
<c>* Load the GC-AD model.</c>
<c></c>
<c></c>
<c></c>
<c></c>
<c></c>
</body>
<docu id="load_dataset_and_model">
<short lang="en_US">Load the Global Context Anomaly Detection model and preprocess the dataset.</short>
<parameters>
<parameter id="DLDataset"/>
<parameter id="DLModelHandle"/>
<parameter id="DLPreprocessParam"/>
<parameter id="ImageDir"/>
<parameter id="ImageHeight"/>
<parameter id="ImageSubDirs"/>
<parameter id="ImageWidth"/>
<parameter id="PatchSize"/>
<parameter id="PreprocessDir"/>
<parameter id="TrainedModel"/>
</parameters>
</docu>
</procedure>
<procedure name="preprocess_dl_samples_bottle">
<interface>
<ic>
<par name="DLSamples" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c></c>
<c>* This procedure performs a segmentation using a threshold to</c>
<c>* remove the white background. This improves the performance</c>
<c>* of the anomaly detection model.</c>
<c></c>
<c>* Loop over all samples in the dataset.</c>
<l>for SampleIndex := 0 to |DLSamples| - 1 by 1</l>
<c>    * DLSample is a handle(dict), so we get a shallow copy here.</c>
<c>    * By changing it we are changing DLSamples.</c>
<l>    DLSample := DLSamples[SampleIndex]</l>
<c></c>
<c>    * Since anomalies are only located on the bottles we exclude</c>
<c>    * the white areas surrounding the bottles.</c>
<l>    rgb1_to_gray (DLSample.image, GrayImage)</l>
<l>    threshold (GrayImage, CenterRegion, 'min', 1.5)</l>
<l>    fill_up (CenterRegion, CenterRegionFillUp)</l>
<l>    reduce_domain (DLSample.image, CenterRegionFillUp, DLSample.image)</l>
<l>endfor</l>
<c></c>
<l>return ()</l>
</body>
<docu id="preprocess_dl_samples_bottle">
<parameters>
<parameter id="DLSamples"/>
</parameters>
</docu>
</procedure>
</hdevelop>
